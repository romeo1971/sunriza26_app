# Dynamics Performance & Kosten-Analyse

**Stand:** 17.10.2025, 01:15 Uhr  
**System:** Modal.com + LivePortrait + GPU (Tesla T4)

---

## ğŸ“Š Aktuelle Performance (Production)

### â±ï¸ Gemessene Zeiten (Tesla T4 GPU):

| Komponente | Zeit | Anteil |
|------------|------|--------|
| **LivePortrait (GPU)** | **60-90s** | **~80%** |
| Download/Trim | ~5s | ~7% |
| Post-Processing (H.264) | ~8s | ~10% |
| Upload zu Firebase | ~2s | ~3% |
| **GESAMT** | **~70-110s** | **100%** |

### ğŸ“ˆ Schwankungen (60-110s):

Die Zeitunterschiede kommen von:

1. **Video-KomplexitÃ¤t:**
   - Viele Gesichts-Bewegungen â†’ lÃ¤nger
   - Statisches Gesicht â†’ kÃ¼rzer

2. **Video-AuflÃ¶sung:**
   - `source-max-dim: 1600` â†’ ~90s
   - `source-max-dim: 1024` â†’ ~70s
   - `source-max-dim: 512` â†’ ~40s (schlechte QualitÃ¤t!)

3. **Modal Container Status:**
   - **Cold Start** (neuer Container) â†’ +10-20s
   - **Warm Start** (bestehender Container) â†’ Baseline

4. **Gesichts-Position:**
   - Gesicht zentral im Bild â†’ schneller
   - Gesicht am Rand â†’ langsamer (mehr Crop-Arbeit)

---

## ğŸ”¥ GPU-Vergleich & Benchmarks

### Offizielle LivePortrait Benchmarks (10s Video):

| Hardware | Zeit | Kosten/h | Speedup | Empfehlung |
|----------|------|----------|---------|------------|
| **CPU (8 Cores)** | 150-200s | $0.10 | Baseline | âŒ Zu langsam |
| **T4 GPU** | **60-90s** | **$0.60** | **2.5x** | âœ… **OPTIMAL** |
| **A10G GPU** | 30-40s | $1.50 | 5x | ğŸ’° FÃ¼r High-Traffic |
| **A100 GPU** | 20-30s | $4.00 | 7x | ğŸ’¸ Nur fÃ¼r extreme Last |

### ğŸ¯ Unsere Wahl: **Tesla T4**

**Warum T4?**
- âœ… **Balance:** Gute Performance zu akzeptablen Kosten
- âœ… **Stabil:** 60-90s ist vorhersehbar
- âœ… **VerfÃ¼gbar:** Keine Wartezeiten bei Modal.com
- âœ… **Kosten:** $0.60/h = ~$0.01-0.015 pro Request

**Wann upgraden auf A10G?**
- Wenn >100 Requests/Tag
- Wenn 30-40s kritisch sind
- Wenn User-Feedback negativ wegen Wartezeit

---

## ğŸ’° Kosten-Kalkulation

### Pro Request (70s average):

```
T4 GPU: $0.60/h
70 Sekunden = 0.0194 Stunden
Kosten: $0.60 * 0.0194 = $0.01164 pro Request
```

### Monatliche Szenarien:

| Requests/Tag | Requests/Monat | Kosten/Monat (T4) | Kosten/Monat (A10G) |
|--------------|----------------|-------------------|---------------------|
| 10 | 300 | **$3.50** | $8.75 |
| 50 | 1,500 | **$17.50** | $43.75 |
| 100 | 3,000 | **$35.00** | $87.50 |
| 500 | 15,000 | **$175.00** | $437.50 |
| 1,000 | 30,000 | **$350.00** | $875.00 |

### ğŸ¯ Break-Even-Analyse:

**Wann lohnt sich A10G?**
- **Niemals rein finanziell!** (2.5x teurer fÃ¼r 2x Speed)
- **Nur fÃ¼r UX:** Wenn 30-40s kritisch sind

**Empfehlung:**
- **MVP/Beta:** T4 ($3-20/Monat) âœ…
- **Produktion (<1000 Requests/Tag):** T4 ($35-350/Monat) âœ…
- **High-Traffic (>1000 Requests/Tag):** A10G erwÃ¤gen

---

## ğŸš€ Optimierungs-Versuche & Erkenntnisse

### âœ… Was wir implementiert haben:

1. **NVIDIA CUDA 12.6 Base Image** â†’ GPU aktiv
2. **onnxruntime-gpu** â†’ CUDAExecutionProvider aktiv
3. **TensorRT Environment Variables** â†’ TensorRT verfÃ¼gbar
4. **TensorRT Cache Volume** â†’ FÃ¼r wiederholte Requests
5. **FP16 Precision** â†’ Schnellere Berechnungen
6. **GPU Verification beim Build** â†’ Sicherheit

### âš ï¸ Was NICHT funktioniert hat:

1. **TensorRT Speedup:**
   - **Theorie:** 2-3x schneller als CUDA
   - **RealitÃ¤t:** LivePortrait nutzt InsightFace mit ONNX, das TensorRT NICHT aktiv nutzt
   - **Ergebnis:** Kein messbarer Speedup

2. **TensorRT Cache:**
   - **Theorie:** Wiederholte Requests laden Engines aus Cache
   - **RealitÃ¤t:** Jedes Video ist anders â†’ neue Engine-Kompilierung
   - **Ergebnis:** Cache wird nicht genutzt (nicht denselben Avatar/Video mehrfach generieren)

3. **Batch Processing:**
   - **Theorie:** Mehrere Frames gleichzeitig verarbeiten
   - **RealitÃ¤t:** LivePortrait hat interne Batch-Size, nicht Ã¤nderbar via CLI
   - **Ergebnis:** Keine Optimierung mÃ¶glich

### âœ… Was WIRKLICH geholfen hat:

1. **GPU statt CPU:** 150s â†’ 70s (2.5x schneller!) âœ…
2. **CUDA 12.6 + onnxruntime-gpu:** Stabil, keine AbstÃ¼rze âœ…
3. **Modal.com statt Cloud Run:** ZuverlÃ¤ssiges Deployment âœ…

---

## ğŸ“ Technische Details

### LivePortrait Workflow (intern):

```
1. Face Detection (InsightFace ONNX)    â†’ ~5s  (GPU)
2. Motion Extraction                     â†’ ~10s (GPU)
3. Frame-by-Frame Animation              â†’ ~43s (GPU) â† HAUPTZEIT!
4. Concatenation + Audio Merge           â†’ ~3s  (CPU)
5. Post-Processing (FFmpeg H.264)        â†’ ~8s  (CPU)
```

**Bottleneck:** Frame-by-Frame Animation (43s von 70s)
- Verarbeitet jedes Frame einzeln
- Nutzt CUDA fÃ¼r Inferenz
- **NICHT parallelisierbar** (sequentielle Verarbeitung)

### Warum TensorRT nicht hilft:

TensorRT ist ein **Inference Optimizer**, der:
- ONNX Modelle in optimierte "Engines" kompiliert
- **Nur fÃ¼r statische Inputs** effektiv (gleiche Batch-Size, gleiche AuflÃ¶sung)

LivePortrait hat:
- **Dynamische Inputs** (verschiedene Videos, verschiedene Gesichter)
- **Verschiedene AuflÃ¶sungen** (je nach `source-max-dim`)
- **Verschiedene Frame-Counts** (je nach Video-LÃ¤nge)

**Ergebnis:** TensorRT muss fÃ¼r jedes Video neu kompilieren â†’ kein Speed-Vorteil!

---

## ğŸ¯ Empfehlungen fÃ¼r Production

### Option 1: **T4 GPU beibehalten** (EMPFOHLEN) âœ…

**Pro:**
- âœ… Stabile 70-90s Performance
- âœ… GÃ¼nstig ($0.01-0.015/Request)
- âœ… Keine Wartezeiten
- âœ… Ausreichend fÃ¼r MVP/Beta

**Contra:**
- â±ï¸ 70-90s kÃ¶nnen als "langsam" wahrgenommen werden
- ğŸ“± User mÃ¼ssen 1-2 Minuten warten

**User Experience verbessern:**
1. âœ… **Countdown Timer** (bereits implementiert: 120s)
2. âœ… **Progress Indicator** (bereits vorhanden)
3. ğŸ’¡ **Background Processing:** User kann App weiter nutzen
4. ğŸ’¡ **Push Notification:** Benachrichtigung wenn fertig
5. ğŸ’¡ **Estimate Time:** "Noch ca. 45 Sekunden..."

### Option 2: **Upgrade auf A10G GPU** ğŸ’°

**Nur wenn:**
- User-Feedback negativ wegen Wartezeit
- >100 Requests/Tag
- Budget fÃ¼r $87-875/Monat verfÃ¼gbar

**Implementierung:**
```python
@app.function(
    image=image,
    gpu="A10G",  # Statt "T4"
    timeout=600,
)
```

**Erwartete Performance:**
- LivePortrait: 30-40s (statt 70s)
- GESAMT: ~45-55s (statt 85s)
- **50% schneller, 2.5x teurer**

### Option 3: **Video kÃ¼rzen** (5s statt 10s) ğŸ¬

**Pro:**
- âœ… 50% weniger Frames â†’ ~35-45s LivePortrait
- âœ… Keine zusÃ¤tzlichen Kosten
- âœ… Kleinere Dateien â†’ schnellerer Upload

**Contra:**
- âŒ Weniger Gesichts-Bewegungen im Hero-Video
- âŒ Weniger "natÃ¼rlich" wirkende Animation
- âŒ User muss Video vorher trimmen

**Implementierung:**
```python
# In modal_dynamics.py, Zeile ~180
subprocess.run([
    'ffmpeg', '-i', hero_video_path,
    '-ss', '0', '-t', '5',  # Statt '-t', '10'
    '-c:v', 'copy', '-y', trimmed_video_path
])
```

---

## ğŸ“Š User-Erwartungs-Management

### Vergleich mit anderen Apps:

| App | Video-Generierung | Wartezeit |
|-----|-------------------|-----------|
| **Sunriza (T4)** | Live Avatar Dynamics | **70-90s** |
| Runway Gen-2 | AI Video | 60-120s |
| Pika Labs | Text-to-Video | 90-180s |
| D-ID | Talking Avatar | 20-40s (nur Gesicht) |
| HeyGen | AI Avatar | 60-90s |

**Erkenntnis:** 70-90s ist **NORMAL** fÃ¼r AI Video-Generierung mit hoher QualitÃ¤t!

### UX Best Practices:

1. âœ… **Transparenz:** "Dein Avatar wird erstellt... dauert ca. 1-2 Minuten"
2. âœ… **Ablenkung:** "WÃ¤hrenddessen kannst du..." (andere Features zeigen)
3. âœ… **Progress:** Countdown Timer mit Fortschrittsbalken
4. âœ… **Erwartung setzen:** "High-Quality AI Rendering braucht Zeit"
5. âŒ **NICHT sagen:** "Bitte warten..." (negativ)

---

## ğŸ”® Zukunfts-Optimierungen

### MÃ¶gliche Improvements (langfristig):

1. **Modal.com GPU Upgrade:**
   - Warten auf H100 GPU Support (~10x schneller)
   - Oder neue GPU-Generation (Ada Lovelace)

2. **LivePortrait Model Optimization:**
   - Warten auf LivePortrait v2 (hoffentlich schneller)
   - Oder eigenes Model fine-tunen

3. **Pre-Processing:**
   - Hero-Video einmal vorverarbeiten
   - Motion Template cachen
   - Bei erneuter Generierung: nur neu rendern (~30s statt 70s)

4. **Distributed Processing:**
   - Face Detection auf CPU-Worker
   - Animation auf GPU-Worker
   - Parallele Verarbeitung â†’ theoretisch 30% schneller

---

## âœ… Fazit

### Aktuelle Situation:
- âœ… **GPU ist optimal konfiguriert** (CUDA, onnxruntime-gpu)
- âœ… **Performance ist normal** fÃ¼r LivePortrait auf T4 GPU
- âœ… **Kosten sind gÃ¼nstig** ($0.01/Request)
- âš ï¸ **70-90s kann als langsam empfunden werden**

### Empfehlung:
1. **T4 GPU beibehalten** fÃ¼r MVP/Beta âœ…
2. **UX verbessern** (Background Processing, Push Notifications) ğŸ””
3. **User-Feedback sammeln** Ã¼ber Wartezeit ğŸ“Š
4. **Bei Bedarf upgraden** auf A10G (spÃ¤ter) ğŸ’°

### Quick Wins (ohne Code-Ã„nderung):
- âœ… Countdown Timer (bereits implementiert)
- ğŸ’¡ "Dein Avatar wird erstellt - dauert ca. 90 Sekunden"
- ğŸ’¡ "In der Zwischenzeit kannst du deinen Chat einrichten"
- ğŸ’¡ Push Notification wenn fertig

---

**Letzte Aktualisierung:** 17.10.2025, 01:20 Uhr  
**Getestet mit:** Modal.com, Tesla T4, LivePortrait, 10s Hero-Video  
**Ergebnis:** 70-90s ist OPTIMAL fÃ¼r T4 GPU - weitere Optimierung nur mit teurerem Hardware mÃ¶glich


