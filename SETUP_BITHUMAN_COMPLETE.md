# ğŸš€ BitHuman + ElevenLabs + Pinecone - COMPLETE SETUP

## âœ… WAS WIR HABEN:

- **BitHuman Cloud**: Avatar Video + Lipsync
- **ElevenLabs**: Custom Voice Clones
- **Pinecone**: Primary Knowledge Base
- **OpenAI**: Fallback wenn Pinecone keine Antwort hat
- **LiveKit Cloud**: Real-time Communication
- **Modal.com**: Agent Hosting
- **Firebase**: Config + Voice ID Storage

---

## ğŸ“‹ SETUP - SCHRITT FÃœR SCHRITT:

### **SCHRITT 1: Modal CLI installieren**

```bash
pip install modal
modal setup
```

Folge den Anweisungen zum Login.

---

### **SCHRITT 2: Modal Secrets erstellen**

```bash
# 1. LiveKit Cloud
modal secret create livekit-cloud \
  LIVEKIT_URL="wss://sunriza-fkglxhd8.livekit.cloud" \
  LIVEKIT_API_KEY="APIfVjpxaNtEGxJ" \
  LIVEKIT_API_SECRET="IhrLivekitSecret"

# 2. BitHuman API
modal secret create bithuman-api \
  BITHUMAN_API_SECRET="sk_bh_IhrBithumanSecret"

# 3. OpenAI API
modal secret create openai-api \
  OPENAI_API_KEY="sk-proj_IhrOpenAIKey"

# 4. ElevenLabs API
modal secret create elevenlabs-api \
  ELEVENLABS_API_KEY="IhrElevenLabsKey" \
  ELEVEN_DEFAULT_VOICE_ID="pNInz6obpgDQGcFmaJgB"

# 5. Pinecone API
modal secret create pinecone-api \
  PINECONE_API_KEY="IhrPineconeKey" \
  PINECONE_INDEX_NAME="sunriza-knowledge"

# 6. Firebase Admin (WICHTIG: JSON als String!)
modal secret create firebase-admin \
  FIREBASE_CREDENTIALS='{"type":"service_account","project_id":"sunriza-26","private_key_id":"...","private_key":"-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n","client_email":"firebase-adminsdk-...@sunriza-26.iam.gserviceaccount.com","client_id":"...","auth_uri":"https://accounts.google.com/o/oauth2/auth","token_uri":"https://oauth2.googleapis.com/token","auth_provider_x509_cert_url":"https://www.googleapis.com/oauth2/v1/certs","client_x509_cert_url":"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-...%40sunriza-26.iam.gserviceaccount.com","universe_domain":"googleapis.com"}'
```

**âš ï¸ Firebase Credentials JSON holen:**
```bash
# Firebase Console â†’ Project Settings â†’ Service Accounts â†’ Generate new private key
# Kopiere den kompletten JSON Content (alles zwischen { ... })
```

---

### **SCHRITT 3: Agent auf Modal deployen**

```bash
cd /Users/hhsw/Desktop/sunriza/sunriza26
modal deploy modal_bithuman_final.py
```

**Output:**
```
âœ“ Created objects.
â”œâ”€â”€ ğŸ”¨ Created mount /Users/hhsw/Desktop/sunriza/sunriza26/modal_bithuman_final.py
â””â”€â”€ ğŸ”¨ Created function start_agent => bithuman-complete-agent-start-agent
â””â”€â”€ ğŸ”¨ Created web function join => https://romeo1971--bithuman-complete-agent-join.modal.run
â””â”€â”€ ğŸ”¨ Created web function health => https://romeo1971--bithuman-complete-agent-health.modal.run

âœ… App deployed!
```

**Notiere die URL:** `https://romeo1971--bithuman-complete-agent-join.modal.run`

---

### **SCHRITT 4: Flutter .env anpassen**

Ã–ffne `/Users/hhsw/Desktop/sunriza/sunriza26/.env`:

```env
# WICHTIG: Setze die Modal URL als Orchestrator
ORCHESTRATOR_URL=https://romeo1971--bithuman-complete-agent-join.modal.run

# Andere Settings bleiben
LIVEKIT_ENABLED=1
LIVEKIT_URL=wss://sunriza-fkglxhd8.livekit.cloud
```

**ODER** wenn ihr `AppConfig.orchestratorUrl` nutzt, Ã¤ndert das in der Config.

---

### **SCHRITT 5: Test - Agent manuell starten**

```bash
# Health Check
curl https://romeo1971--bithuman-complete-agent-health.modal.run

# Agent fÃ¼r Test-Room starten
curl -X POST https://romeo1971--bithuman-complete-agent-join.modal.run \
  -H "Content-Type: application/json" \
  -d '{
    "room": "test-room-123",
    "agent_id": "A91XMB7113"
  }'
```

**Expected Response:**
```json
{
  "status": "started",
  "room": "test-room-123",
  "agent_id": "A91XMB7113"
}
```

---

### **SCHRITT 6: Firebase Daten prÃ¼fen**

Jeder Avatar braucht:

```javascript
// Firebase: avatars/{avatarId}
{
  liveAvatar: {
    agentId: "A91XMB7113"  // â† WICHTIG!
  },
  training: {
    voice: {
      elevenVoiceId: "pNInz6obpgDQGcFmaJgB",  // â† ElevenLabs Voice
      cloneVoiceId: "pNInz6obpgDQGcFmaJgB"     // â† Falls geklont
    }
  },
  userId: "user123",  // â† FÃ¼r Pinecone Namespace
  name: "Mein Avatar",
  personality: "Du bist ein freundlicher Assistent..."  // â† Optional
}
```

---

### **SCHRITT 7: Pinecone Index prÃ¼fen**

```bash
# Pinecone Console: https://app.pinecone.io
# Index Name: sunriza-knowledge
# Dimension: 1536 (fÃ¼r text-embedding-ada-002)
# Metric: cosine
```

**Namespace Format:** `{userId}_{avatarId}` (z.B. `user123_abc456`)

---

### **SCHRITT 8: Flutter App testen**

```bash
# Flutter App starten
cd /Users/hhsw/Desktop/sunriza/sunriza26
flutter run

# Im App:
1. WÃ¤hle Avatar
2. Klicke "GesprÃ¤ch starten"
3. Warte auf LiveKit Connection
4. Agent startet automatisch
5. Spreche mit Avatar!
```

---

## ğŸ¬ ABLAUF WENN USER KLICKT:

```
1. Flutter: User klickt "GesprÃ¤ch starten"
   â†“
2. Flutter â†’ Backend: POST /livekit/token
   Response: {token, room, url}
   â†“
3. Flutter â†’ LiveKit: Room Join
   âœ… Connected to room-abc123
   â†“
4. Flutter â†’ Modal: POST /join
   Body: {room: "room-abc123", agent_id: "A91XMB7113"}
   â†“
5. Modal Agent startet:
   â”œâ”€â”€ LÃ¤dt Firebase Config (Voice ID, Namespace)
   â”œâ”€â”€ Initialisiert Pinecone (mit Namespace)
   â”œâ”€â”€ Initialisiert ElevenLabs TTS
   â”œâ”€â”€ Joined LiveKit Room
   â”œâ”€â”€ Startet BitHuman Avatar
   â””â”€â”€ Bereit fÃ¼r Conversation
   â†“
6. User spricht â†’ Agent antwortet:
   â”œâ”€â”€ STT: User Audio â†’ Text
   â”œâ”€â”€ Pinecone: Query Knowledge Base
   â”œâ”€â”€ LLM: Falls Pinecone keine Antwort â†’ OpenAI
   â”œâ”€â”€ TTS: Text â†’ ElevenLabs Voice
   â”œâ”€â”€ BitHuman: Audio â†’ Lipsync Video
   â””â”€â”€ User sieht/hÃ¶rt Avatar
```

---

## ğŸ” TROUBLESHOOTING:

### **Agent startet nicht:**

```bash
# Modal Logs checken
modal app logs bithuman-complete-agent

# Oder real-time
modal run modal_bithuman_final.py::start_agent --room test --agent-id A91XMB7113
```

### **Keine Voice / Falshe Voice:**

1. PrÃ¼fe Firebase: `training.voice.elevenVoiceId`
2. PrÃ¼fe Modal Secret: `ELEVEN_DEFAULT_VOICE_ID`
3. PrÃ¼fe ElevenLabs API Key

### **Pinecone antwortet nicht:**

1. PrÃ¼fe Namespace: `{userId}_{avatarId}`
2. PrÃ¼fe ob Daten im Index: Pinecone Console
3. PrÃ¼fe Embedding Model: `text-embedding-ada-002`

### **BitHuman Avatar zeigt nicht:**

1. PrÃ¼fe `BITHUMAN_API_SECRET`
2. PrÃ¼fe `liveAvatar.agentId` in Firebase
3. PrÃ¼fe BitHuman Credits

---

## ğŸ’° KOSTEN PRO CONVERSATION (ca. 10 Min):

- **Modal Agent**: ~$0.09 (CPU + Memory)
- **BitHuman Cloud**: ~$X (eure Credits)
- **ElevenLabs TTS**: ~$0.30 (Character-based)
- **OpenAI Realtime**: ~$0.60 (Audio Minuten)
- **Pinecone Query**: ~$0.01 (Queries)

**Total**: ~$1.00 - $2.00 pro 10-Min Conversation

**Optimization:**
- Modal `keep_warm=1` â†’ Schnellere Starts
- Pinecone Cache â†’ Weniger OpenAI Calls
- Agent Auto-Shutdown nach InaktivitÃ¤t

---

## âœ… SUCCESS CHECKLIST:

- [ ] Modal CLI installiert
- [ ] Alle 6 Modal Secrets erstellt
- [ ] Agent deployed (URL notiert)
- [ ] Flutter .env aktualisiert
- [ ] Firebase Daten geprÃ¼ft (`liveAvatar.agentId`, `training.voice`)
- [ ] Pinecone Index existiert
- [ ] Test Agent Start funktioniert
- [ ] Flutter App startet
- [ ] Conversation funktioniert!

---

## ğŸ¯ ERFOLG = WENN:

1. âœ… User klickt "GesprÃ¤ch starten"
2. âœ… Flutter connected zu LiveKit
3. âœ… Modal Agent startet automatisch
4. âœ… User sieht BitHuman Avatar Video
5. âœ… User hÃ¶rt ElevenLabs Custom Voice
6. âœ… Agent nutzt Pinecone Knowledge Base
7. âœ… Falls Pinecone leer â†’ OpenAI Fallback
8. âœ… Lipsync ist perfekt synchron
9. âœ… Conversation ist natÃ¼rlich und flÃ¼ssig

---

**NEXT STEP:** Modal Secrets erstellen und deployen! ğŸš€

